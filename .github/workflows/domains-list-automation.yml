name: Domains Automation

on:
  schedule:
    - cron: "0 10 * * *"
  push:
    paths:
      - "domains.lst"
      - "sources/sources-domains.txt"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  process-domains:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: sudo apt-get install -y wget curl grep moreutils

      - name: Clean domains.lst
        run: |
          sed -i 's/^[[:space:]]*-[[:space:]]*//' domains.lst
          sed -i '/^[[:space:]]*#/d; /^;/d; /^\/\//d; /^[[:space:]]*--/d' domains.lst
          sed -i 's/^full://g; s|^https\?://||g; s|^//||g' domains.lst
          sed -i 's|/.*$||g; s|:.*$||g; s|^www[2-9]\?\.||g' domains.lst
          sed -i 's/^[[:space:]]*//; s/[[:space:]]*$//; /^$/d' domains.lst

      - name: Sort domains.lst
        run: LC_COLLATE=C sort -f -u domains.lst -o domains.lst

      - name: Filter subdomains in domains.lst
        run: |
          get_parents() {
            local d=$1
            while [[ $d == *.* ]]; do
              d=${d#*.}
              echo "$d"
            done
          }
          mapfile -t all < domains.lst
          IFS=$'\n' sorted=($(printf '%s\n' "${all[@]}" |
            awk -F. '{print NF-1, $0}' | sort -n | cut -d' ' -f2-))
          declare -A keep; > filtered.txt
          for dom in "${sorted[@]}"; do
            skip=
            for p in $(get_parents "$dom"); do
              [[ ${keep[$p]} ]] && { skip=1; break; }
            done
            [[ $skip ]] || { echo "$dom" >> filtered.txt; keep[$dom]=1; }
          done
          sort -u filtered.txt -o domains.lst
          rm filtered.txt

      - name: Compare with external sources
        run: |
          set -eo pipefail
          TMP_DIR="./tmp"
          DOMAINS_FILE="domains.lst"
          SOURCES_FILE="sources/sources-domains.txt"
          OUTPUT_DIR="categories/Compared-Domains"

          cleanup() {
              [ -d "$TMP_DIR" ] && rm -rf "$TMP_DIR"
          }

          mkdir -p "$TMP_DIR" "$OUTPUT_DIR"
          cp "$DOMAINS_FILE" "$TMP_DIR/domains.lst"

          sed -i '/^[[:space:]]*#/d; /^;/d; /^\/\//d; /^[[:space:]]*--/d' "$TMP_DIR/domains.lst"
          sed -i 's/^full://g; s|^https\?://||g; s|^//||g' "$TMP_DIR/domains.lst"
          sed -i 's|/.*$||g; s|:.*$||g; s|^www[2-9]\?\.||g' "$TMP_DIR/domains.lst"
          sed -i 's/^[[:space:]]*//; s/[[:space:]]*$//; /^$/d' "$TMP_DIR/domains.lst"
          LC_ALL=C sort -u "$TMP_DIR/domains.lst" -o "$TMP_DIR/domains.lst"

          declare -A PRIMARY_DOMAINS
          while IFS= read -r d; do
              PRIMARY_DOMAINS["$d"]=1
          done < "$TMP_DIR/domains.lst"

          declare -A SOURCES
          mapfile -t SOURCE_URLS < <(grep -v '^#' "$SOURCES_FILE" | sed 's/#.*//; /^$/d')

          for raw_url in "${SOURCE_URLS[@]}"; do
              url=$(echo "$raw_url" | awk '{print $1}' | xargs)
              [[ "$url" =~ ^https?:// ]] || url="https://$url"
              key=$(echo "$url" | sed 's/[?&].*//; s|https\?://||; s|/|_|g; s/\./_/g; s/_$//')
              SOURCES["$key"]="$url"
          done

          for key in "${!SOURCES[@]}"; do
              url="${SOURCES[$key]}"
              out_file="$TMP_DIR/${key}.lst"
              
              echo "Processing: $url"
              curl -sfL --connect-timeout 30 --retry 3 "$url" > "$out_file" || continue

              sed -i -E '
                  /^[[:space:]]*#/d;
                  /^[[:space:]]*$/d;
                  s/^[0-9.]+\s+//;
                  s/\s+/\n/g;
                  s/[[:space:]]*#.*$//;
                  s/^[[:space:]]*//;
                  s/[[:space:]]*$//;
                  /^[a-zA-Z0-9-]+\.[a-zA-Z]{2,}/!d;
              ' "$out_file"

              sed -i '
                  s|^https\?://||g;
                  s|/.*$||g;
                  s|:.*$||g;
                  s|^www[0-9]*\.||g;
              ' "$out_file"

              LC_ALL=C sort -u "$out_file" -o "$out_file"

              [ -s "$out_file" ] || continue

              filtered=()
              while IFS= read -r domain; do
                  parent="$domain"
                  is_sub=0
                  while [[ "$parent" == *.* ]]; do
                      parent="${parent#*.}"
                      [ -n "${PRIMARY_DOMAINS[$parent]}" ] && { is_sub=1; break; }
                  done
                  [ $is_sub -eq 0 ] && filtered+=("$domain")
              done < "$out_file"
              
              printf "%s\n" "${filtered[@]}" > "${out_file}.filtered"
              mv "${out_file}.filtered" "$out_file"
              [ -s "$out_file" ] || continue


              LC_ALL=C comm -23 \
                  <(LC_ALL=C sort "$out_file") \
                  <(LC_ALL=C sort "$TMP_DIR/domains.lst") > "$TMP_DIR/missing_${key}.txt"

              LC_ALL=C comm -13 \
                  <(LC_ALL=C sort "$out_file") \
                  <(LC_ALL=C sort "$TMP_DIR/domains.lst") > "$TMP_DIR/presence_${key}.txt"
          done

          for type in missing presence; do
              final_file="$OUTPUT_DIR/${type}-domains.txt"
              > "$final_file"
              for key in "${!SOURCES[@]}"; do
                  tmp_file="$TMP_DIR/${type}_${key}.txt"
                  [ -s "$tmp_file" ] && {
                      source_url="${SOURCES[$key]}"
                      printf "# %s\n# Source: %s\n\n" "${type^} domains" "$source_url" >> "$final_file"
                      cat "$tmp_file" | sed 's/^/- /' >> "$final_file"
                      printf "\n\n" >> "$final_file"
                  }
              done
              sed -i -e '/^$/N;/^\n$/D' "$final_file"
          done

          cleanup

      - name: Generate domains without YouTube
        run: |
          yt="categories/Services/youtube/youtube-domains.lst"
          [[ -f "$yt" && -f domains.lst ]] && grep -vxFf "$yt" domains.lst > domains-without-yt.lst

      - name: Commit and push .lst changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          for f in domains.lst domains-nekobox.lst domains-without-yt.lst; do
            [[ -f $f ]] && git add "$f"
          done
          git commit -m "Update domain lists" || echo "No changes to commit"
          git push origin main

      - name: Commit and push Compared-Domains changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          for f in categories/Compared-Domains/missing-domains.txt categories/Compared-Domains/presence-domains.txt; do
            [[ -f $f ]] && git add "$f"
          done
          git commit -m "Domain comparison: $(date +'%Y-%m-%d')" || echo "No comparison changes"
          git push origin main

  generate-srs:
    runs-on: ubuntu-24.04
    needs: process-domains
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Pull latest changes
        run: git pull origin main

      - name: Compile ruleset SRS
        run: |
          docker run --rm \
            -v ${{ github.workspace }}:/app \
            itdoginfo/compilesrs:0.1.11 \
            python3 /app/scripts/convert.py

      - name: Move generated file
        run: |
          mkdir -p categories/Rulesets
          mv domains-cidr4.srs categories/Rulesets/

      - name: Commit SRS changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add categories/Rulesets/domains-cidr4.srs
          git commit -m "Update SRS ruleset: $(date +'%d.%m.%Y %H:%M')" || echo "No SRS changes"
          git push origin main

  generate-routing-nekobox-config:
    runs-on: ubuntu-latest
    needs: generate-srs
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Generate routing config JSON
        run: |
          rm -f categories/Rulesets/nekoray-mahdi.json
          tmp_file=$(mktemp)

          cat << 'EOF' > "$tmp_file"
          {
              "id": 222222223,
              "name": "routing",
              "rules": [
                  {
                      "actionType": "hijack-dns",
                      "invert": false,
                      "ip_is_private": false,
                      "ip_version": "",
                      "name": "rule_1",
                      "network": "",
                      "noDrop": false,
                      "outboundID": -2,
                      "override_address": "",
                      "override_port": 0,
                      "protocol": "dns",
                      "rejectMethod": "",
                      "simple_action": 0,
                      "sniffOverrideDest": false,
                      "source_ip_is_private": false,
                      "strategy": "",
                      "type": 0
                  },
                  {
                      "actionType": "route",
                      "domain_suffix": [
          EOF

          mapfile -t domains < domains.lst
          domain_entries=()
          for i in "${!domains[@]}"; do
            domain="\"${domains[$i]}\""
            if [ "$i" -lt $((${#domains[@]} - 1)) ]; then
                domain_entries+=("                $domain,")
            else
                domain_entries+=("                $domain")
            fi
          done

          (IFS=$'\n'; printf "%s\n" "${domain_entries[@]}") >> "$tmp_file"

          cat << 'EOF' >> "$tmp_file"
                      ],
                      "invert": false,
                      "ip_is_private": false,
                      "ip_version": "",
                      "name": "rule_2",
                      "network": "",
                      "noDrop": false,
                      "outboundID": -1,
                      "override_address": "",
                      "override_port": 0,
                      "protocol": "",
                      "rejectMethod": "",
                      "simple_action": 0,
                      "sniffOverrideDest": false,
                      "source_ip_is_private": false,
                      "strategy": "",
                      "type": 0
                  },
                  {
                      "actionType": "route",
                      "invert": false,
                      "ip_cidr": [
          EOF

          mapfile -t cidrs < categories/CIDR4/summary.lst
          cidr_entries=()
          for i in "${!cidrs[@]}"; do
            cidr="\"${cidrs[$i]}\""
            if [ "$i" -lt $((${#cidrs[@]} - 1)) ]; then
              cidr_entries+=("                $cidr,")
            else
              cidr_entries+=("                $cidr")
            fi
          done
          (IFS=$'\n'; printf "%s\n" "${cidr_entries[@]}") >> "$tmp_file"

          cat << 'EOF' >> "$tmp_file"
                      ],
                      "ip_is_private": false,
                      "ip_version": "",
                      "name": "rule_3",
                      "network": "",
                      "noDrop": false,
                      "outboundID": -1,
                      "override_address": "",
                      "override_port": 0,
                      "protocol": "",
                      "rejectMethod": "",
                      "simple_action": 1600940404,
                      "sniffOverrideDest": false,
                      "source_ip_is_private": false,
                      "strategy": "",
                      "type": 0
                  },
                  {
                      "actionType": "route",
                      "invert": false,
                      "ip_is_private": false,
                      "ip_version": "",
                      "name": "rule_4",
                      "network": "",
                      "noDrop": false,
                      "outboundID": -1,
                      "override_address": "",
                      "override_port": 0,
                      "process_name": [
                          "Discord.exe"
                      ],
                      "protocol": "",
                      "rejectMethod": "",
                      "simple_action": 0,
                      "sniffOverrideDest": false,
                      "source_ip_is_private": false,
                      "strategy": "",
                      "type": 0
                  }
              ]
          }
          EOF

          mkdir -p categories/Rulesets
          mv "$tmp_file" categories/Rulesets/nekoray-mahdi.json

      - name: Commit and push routing config
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add categories/Rulesets/nekoray-mahdi.json
          git commit -m "Update routing config: $(date +'%d.%m.%Y %H:%M')" || echo "No config changes"
          git push origin main

  process-subnets:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: sudo apt-get update && sudo apt-get install -y curl

      - name: Create directory structure
        run: mkdir -p categories/CIDR4 categories/CIDR6

      - name: Extract Cloudflare networks
        run: |
          curl -sSfL "https://www.cloudflare.com/ips-v4" | sort -u > categories/CIDR4/cloudflare.lst
          curl -sSfL "https://www.cloudflare.com/ips-v6" | sort -u > categories/CIDR6/cloudflare.lst

      - name: Extract Discord CIDRs
        run: |
          curl -sSfL "https://iplist.opencck.org/?format=text&data=cidr4&site=discord.gg&site=discord.media" | sort -u > categories/CIDR4/discord.lst
          curl -sSfL "https://iplist.opencck.org/?format=text&data=cidr6&site=discord.gg&site=discord.media" | sort -u > categories/CIDR6/discord.lst

      - name: Extract Telegram networks
        run: |
          TEMP_FILE=$(mktemp)
          curl -sSfL "https://core.telegram.org/resources/cidr.txt" > "$TEMP_FILE"
          grep -F '.' "$TEMP_FILE" | sort -u > categories/CIDR4/telegram.lst
          grep -F ':' "$TEMP_FILE" | sort -u > categories/CIDR6/telegram.lst
          rm "$TEMP_FILE"

      - name: Download BGP data
        run: curl -sSfL "https://bgp.tools/table.txt" > bgp_table.txt

      - name: Extract Meta networks
        run: |
          awk '/32934$/ {print $1}' bgp_table.txt | grep -F '.' | sort -u > categories/CIDR4/meta.lst
          awk '/32934$/ {print $1}' bgp_table.txt | grep -F ':' | sort -u > categories/CIDR6/meta.lst

      - name: Extract Twitter networks
        run: |
          awk '/13414$/ {print $1}' bgp_table.txt | grep -F '.' | sort -u > categories/CIDR4/twitter.lst
          awk '/13414$/ {print $1}' bgp_table.txt | grep -F ':' | sort -u > categories/CIDR6/twitter.lst

      - name: Extract Hetzner networks
        run: |
          awk '/24940$/ {print $1}' bgp_table.txt | grep -F '.' | sort -u > categories/CIDR4/hetzner.lst
          awk '/24940$/ {print $1}' bgp_table.txt | grep -F ':' | sort -u > categories/CIDR6/hetzner.lst

      - name: Extract OVH networks
        run: |
          awk '/16276$/ {print $1}' bgp_table.txt | grep -F '.' | sort -u > categories/CIDR4/ovh.lst
          awk '/16276$/ {print $1}' bgp_table.txt | grep -F ':' | sort -u > categories/CIDR6/ovh.lst

      - name: Generate summaries
        run: |
          cat categories/CIDR4/{cloudflare,discord,meta,twitter}.lst | sort -u > categories/CIDR4/summary.lst
          cat categories/CIDR6/{cloudflare,discord,meta,twitter}.lst | sort -u > categories/CIDR6/summary.lst
          rm bgp_table.txt

      - name: Commit changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add categories/CIDR* categories/Rulesets/nekoray-mahdi.json
          git commit -m "Update CIDR lists" || echo "No changes to commit"
          git push origin main